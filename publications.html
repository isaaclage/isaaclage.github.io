<!DOCTYPE html>
<html>

<head>
    <title>Isaac Lage</title>

    <link type="text/css" rel="stylesheet" href="css/main.css" />
</head>

<body>

    <div id="name">
        <h1>Isaac Lage (he/they)</h1>
        <p><b>Email:</b> isaaclage at g.harvard.edu &nbsp; | &nbsp; <b><a href="cv_lage.pdf">CV</a></b></p>
        <p><b><a href="index.html">Overview</a> &nbsp; | &nbsp; <a href="publications.html">Publications</a> &nbsp; | &nbsp; <a href="teaching-experience.html">Teaching Experience</a></b></p>
    </div>

    <hr>

    <div id="body">
        <div id="photo">
            <img src="images/photo.jpg", id="photo">
        </div>

        <div id="summary">

        <div id="publications">
            <p id="publications">
                <p><b>Publications:</b>

                <ul>

                <li><b>Lage, I.</b>, McCoy, T. H., Perlis, R. H., Doshi-Velez F. <a href="https://www.sciencedirect.com/science/article/pii/S0165032722001951?via%3Dihub">Efficiently identifying individuals at high risk for treatment resistance in major depressive disorder using electronic health records.</a> Journal of Affective Disorders Volume 306. 2022.<b>(Editor's choice article)</b></li>

                <li><b>Lage, I.</b>, Pradier, M. F., McCoy, T. H., Perlis, R. H., Doshi-Velez F. <a href="https://www.sciencedirect.com/science/article/abs/pii/S0165032722004724?via%3Dihub">Do clinicians follow heuristics in prescribing antidepressants?</a> Journal of Affective Disorders Volume 311. 2022.</li>

                <li>Mahinpei, A.*, Clark, J.*, <b>Lage, I.</b>, Doshi-Velez, F., Pan, W., <a href="https://arxiv.org/pdf/2106.13314.pdf">Promises and Pitfalls of Black-Box Concept Learning Models.</a> ICML: Workshop on Theoretic Foundation, Criticism, and Application Trend of Explainable AI. 2021. <b>(Mentoring role)</b></li>

                <li><b>Lage, I.</b>, Doshi-Velez, F. <a href="https://arxiv.org/pdf/2012.02898.pdf">Learning interpretable concept-based models with human feedback.</a> ArXiv Pre-print. 2020.</li>

                <li>McGrath, S.*, Mehta, P.*, Zytek, A., <b>Lage, I.</b>, Lakkaraju, H. <a href="https://arxiv.org/pdf/2011.06167.pdf">When does uncertainty matter?: Understanding the impact of predictive uncertainty in ML assisted decision making.</a> ArXiv Pre-print. 2020. <b>(Mentoring role)</b></li>

                <li>Tabac A., Wigell, R., Wolf, K., <b>Lage, I.</b>, Landrum, S., Reyes Nieva, H., Bearnot B., Streed, C. Using Patterns of Missing EHR Data to Identify Care Disparities in Gender Diverse Patients. Abstract at American Public Health Association. 2020.</li>

                <li><b>Lage I*</b>, Chen E*, He J*, Narayanan M*, Gershman S, Kim B, Doshi-Velez F. <a href="https://www.aaai.org/ojs/index.php/HCOMP/article/view/5280/5132">Human Evaluation of Models Built for Interpretability</a>. AAAI Conference on Human Computation and Crowdsourcing (HCOMP). 2019. <b>(Honorable mention for best paper)</b></li>

                <li><b>Lage I*</b>, Lifschitz D*, Doshi-Velez F, Amir O.  <a href="https://www.ijcai.org/proceedings/2019/0194.pdf">Exploring Computational User Models for Agent Policy Summarization.</a> International Joint Conference on Artificial Intelligence (IJCAI). 2019.</li>

                <li><b>Lage I</b>, Lifschitz D, Doshi-Velez F, Amir O.  <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7901849/">Toward Robust Policy Summarization--Extended Abstract.</a> International conference on Autonomous Agents and Multi-Agent Systems (AAMAS). 2019.</li>

                <li><b>Lage I</b>, Ross A, Kim B, Gershman S, Doshi-Velez F. <a href="http://papers.nips.cc/paper/8219-human-in-the-loop-interpretability-prior">Human-in-the-Loop Interpretability Prior.</a> Conference on Neural Information Processing Systems (NeurIPS). 2018. <b>(Selected for spotlight--3.5\% of submitted papers)</b></li>

                <li>Ross AS*, <b>Lage I*</b>, Doshi-Velez F. <a href="https://goo.gl/TwRhXo">The Neural Lasso: Local Linear Sparsity for Interpretable Explanations.</a> Neural Information Processing Systems (NIPS) Workshop on Transparent and Interpretable Machine Learning in Safety Critical Environments. 2017.</li>    
            </p>
         </div>

    </div>

    </div>

</body>
</html>
